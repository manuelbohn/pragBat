---
title: "PragBat Analysis"
output: html_document
---

```{r}
library(tidyverse)
library(knitr)
library(ggthemes)
library(corrr)
library(corrplot)
library(ggcorrplot)
library(reshape2)
library(coda)
library(blavaan)
library(brms)
library(ggpubr)
library(scales)
library(tidyboot)
library(ggridges)


estimate_mode <- function(s) {
  d <- density(s)
  return(d$x[which.max(d$y)])
}


hdi_upper<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","upper"])
}

hdi_lower<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","lower"])
}
```
# Data

```{r}
data <- bind_rows(
  read_csv("../data/data_r1.csv") %>%filter(task != "training") %>%mutate(study = "study1"),
  read_csv("../data/data_r2.csv") %>%filter(task != "training")%>%mutate(study = "study2"),
  read_csv("../data/data_r3.csv") %>%filter(task != "training")%>%mutate(study = "study3")
  ) %>%
  mutate(study = factor(study),
         id = paste(study, id, sep = "_"),
         test_day = factor(test_day))
```

# Age effects

In the next section, we run the same model for each task and each study. Model outputs are saved in the repository and can be loaded at the end of the following code section in order to reproduce the exact results from the paper.

```{r}
# Models
# ## card sorting
# bm_cs_s1 <- brm(correct ~ z_age + z_trial + (z_trial|id),
#           family = bernoulli(),
#           #control = list(adapt_delta = 0.99),
#           data = data%>%filter(task == "card_sorting", study == "study1"),
#           sample_prior = F,
#           chains = 4,
#           cores = 4,
#           iter = 4000)%>%
#   add_criterion("waic")
# 
# #saveRDS(bm_cs_s1, "../saves/card_sorting_model_s1.rds")
# 
# bm_cs_s2 <- brm(correct ~ z_age + z_trial + (z_trial|id),
#           family = bernoulli(),
#           #control = list(adapt_delta = 0.99),
#           data = data%>%filter(task == "card_sorting", study == "study2"),
#           sample_prior = F,
#           chains = 4,
#           cores = 4,
#           iter = 4000)%>%
#   add_criterion("waic")
# 
# #saveRDS(bm_cs_s2, "../saves/card_sorting_model_s2.rds")
# 
# bm_cs_s3 <- brm(correct ~ z_age + z_trial + (z_trial|id),
#           family = bernoulli(),
#           #control = list(adapt_delta = 0.99),
#           data = data%>%filter(task == "card_sorting", study == "study3"),
#           sample_prior = F,
#           chains = 4,
#           cores = 4,
#           iter = 4000)%>%
#   add_criterion("waic")
# 
# #saveRDS(bm_cs_s3, "../saves/card_sorting_model_s3.rds")
# 
# # mutual exclusivity
# bm_me_s1 <- brm(correct ~ z_age + z_trial + (z_trial|id),
#           family = bernoulli(),
#           #control = list(adapt_delta = 0.99),
#           data = data%>%filter(task == "mutual_exclusivity", study == "study1"),
#           sample_prior = F,
#           chains = 4,
#           cores = 4,
#           iter = 4000)%>%
#   add_criterion("waic")
# 
# #saveRDS(bm_me_s1, "../saves/mutual_exclusivity_model_s1.rds")
# 
# bm_me_s2 <- brm(correct ~ z_age + z_trial + (z_trial|id),
#           family = bernoulli(),
#           #control = list(adapt_delta = 0.99),
#           data = data%>%filter(task == "mutual_exclusivity", study == "study2"),
#           sample_prior = F,
#           chains = 4,
#           cores = 4,
#           iter = 4000)%>%
#   add_criterion("waic")
# 
# #saveRDS(bm_me_s2, "../saves/mutual_exclusivity_model_s2.rds")
# 
# bm_me_s3 <- brm(correct ~ z_age + z_trial + (z_trial|id),
#           family = bernoulli(),
#           #control = list(adapt_delta = 0.99),
#           data = data%>%filter(task == "mutual_exclusivity", study == "study3"),
#           sample_prior = F,
#           chains = 4,
#           cores = 4,
#           iter = 4000)%>%
#   add_criterion("waic")
# 
# saveRDS(bm_me_s3, "../saves/mutual_exclusivity_model_s3.rds")
# 
# 
# # ad hoc implicature
# bm_ad_s2 <- brm(correct ~ z_age + z_trial + (z_trial|id),
#           family = bernoulli(),
#           #control = list(adapt_delta = 0.99),
#           data = data%>%filter(task == "ad_hoc_implicature", study == "study2"),
#           sample_prior = F,
#           chains = 4,
#           cores = 4,
#           iter = 4000)%>%
#   add_criterion("waic")
# 
# #saveRDS(bm_ad_s2, "../saves/ad_hoc_implicature_model_s2.rds")
# 
# bm_ad_s3 <- brm(correct ~ z_age + z_trial + (z_trial|id),
#           family = bernoulli(),
#           #control = list(adapt_delta = 0.99),
#           data = data%>%filter(task == "ad_hoc_implicature", study == "study3"),
#           sample_prior = F,
#           chains = 4,
#           cores = 4,
#           iter = 4000)%>%
#   add_criterion("waic")
# 
# #saveRDS(bm_ad_s3, "../saves/ad_hoc_implicature_model_s3.rds")
# 
# # discourse_continuity
# bm_dis_s2 <- brm(correct ~ z_age + z_trial + (z_trial|id),
#           family = bernoulli(),
#           #control = list(adapt_delta = 0.99),
#           data = data%>%filter(task == "discourse_continuity", study == "study2"),
#           sample_prior = F,
#           chains = 4,
#           cores = 4,
#           iter = 4000)%>%
#   add_criterion("waic")
# 
# #saveRDS(bm_dis_s2, "../saves/discourse_continuity_model_s2.rds")
# 
# # informativeness
# bm_inf_s1 <- brm(correct ~ z_age + z_trial + (z_trial|id),
#           family = bernoulli(),
#           #control = list(adapt_delta = 0.99),
#           data = data%>%filter(task == "informativeness", study == "study1"),
#           sample_prior = F,
#           chains = 4,
#           cores = 4,
#           iter = 4000)%>%
#   add_criterion("waic")
# 
# #saveRDS(bm_inf_s1, "../saves/informativeness_model_s1.rds")
# 
# #match_to_sample
# bm_ms_s3 <- brm(correct ~ z_age + z_trial + (z_trial|id),
#           family = bernoulli(),
#           #control = list(adapt_delta = 0.99),
#           data = data%>%filter(task == "match_to_sample", study == "study3"),
#           sample_prior = F,
#           chains = 4,
#           cores = 4,
#           iter = 4000)%>%
#   add_criterion("waic")
# 
# #saveRDS(bm_ms_s3, "../saves/match_to_sample_model_s3.rds")
# 
# #novelty
# bm_nov_s1 <- brm(correct ~ z_age + z_trial + (z_trial|id),
#           family = bernoulli(),
#           #control = list(adapt_delta = 0.99),
#           data = data%>%filter(task == "novelty", study == "study1"),
#           sample_prior = F,
#           chains = 4,
#           cores = 4,
#           iter = 4000)%>%
#   add_criterion("waic")
# 
# #saveRDS(bm_nov_s1, "../saves/novelty_model_s1.rds")
# 
# #preference
# bm_pref_s1 <- brm(correct ~ z_age + z_trial + (z_trial|id),
#           family = bernoulli(),
#           #control = list(adapt_delta = 0.99),
#           data = data%>%filter(task == "preference", study == "study1"),
#           sample_prior = F,
#           chains = 4,
#           cores = 4,
#           iter = 4000)%>%
#   add_criterion("waic")
# 
# #saveRDS(bm_pref_s1, "../saves/preference_model_s1.rds")
# 
# #simple_inf
# bm_simpinf_s2 <- brm(correct ~ z_age + z_trial + (z_trial|id),
#           family = bernoulli(),
#           #control = list(adapt_delta = 0.99),
#           data = data%>%filter(task == "simple_inf", study == "study2"),
#           sample_prior = F,
#           chains = 4,
#           cores = 4,
#           iter = 4000)%>%
#   add_criterion("waic")
# 
# #saveRDS(bm_simpinf_s2, "../saves/simple_inf_model_s2.rds")
# 
# bm_simpinf_s3 <- brm(correct ~ z_age + z_trial + (z_trial|id),
#           family = bernoulli(),
#           #control = list(adapt_delta = 0.99),
#           data = data%>%filter(task == "simple_inf", study == "study3"),
#           sample_prior = F,
#           chains = 4,
#           cores = 4,
#           iter = 4000)%>%
#   add_criterion("waic")
# 
# #saveRDS(bm_simpinf_s3, "../saves/simple_inf_model_s3.rds")

# Load saved model outputs
bm_cs_s1 <- readRDS( "../saves/card_sorting_model_s1.rds")
bm_cs_s2 <- readRDS( "../saves/card_sorting_model_s2.rds")
bm_cs_s3 <- readRDS( "../saves/card_sorting_model_s3.rds")

bm_me_s1 <- readRDS( "../saves/mutual_exclusivity_model_s1.rds")
bm_me_s2 <- readRDS( "../saves/mutual_exclusivity_model_s2.rds")
bm_me_s3 <- readRDS( "../saves/mutual_exclusivity_model_s3.rds")

bm_ad_s2 <- readRDS( "../saves/ad_hoc_implicature_model_s2.rds")
bm_ad_s3 <- readRDS( "../saves/ad_hoc_implicature_model_s3.rds")

bm_dis_s2 <- readRDS( "../saves/discourse_continuity_model_s2.rds")

bm_inf_s1 <- readRDS( "../saves/informativeness_model_s1.rds")

bm_nov_s1 <- readRDS( "../saves/novelty_model_s1.rds")

bm_pref_s1 <- readRDS( "../saves/preference_model_s1.rds")

bm_ms_s3 <- readRDS( "../saves/match_to_sample_model_s3.rds")

bm_simpinf_s2 <- readRDS( "../saves/simple_inf_model_s2.rds")
bm_simpinf_s3 <- readRDS( "../saves/simple_inf_model_s3.rds")

```

The following code section produces the model predictions included in Figure 2. 

```{r}
#Predictions
nd1 <- data%>%
  filter(study == "study1", trial == "1", task == "mutual_exclusivity", test_day == 1)%>%
  select(-z_trial,-correct, -task, -test_day, -gender, -item, -subage)%>%
  mutate(z_trial = 0)
nd2 <- data%>%
  filter(study == "study2", trial == "1", task == "mutual_exclusivity", test_day == 1)%>%
  select(-z_trial,-correct, -task, -test_day, -gender, -item, -subage)%>%
  mutate(z_trial = 0)
nd3 <- data%>%
  filter(study == "study3", trial == "1", task == "mutual_exclusivity")%>%
  select(-z_trial,-correct, -task, -test_day, -gender, -item, -subage)%>%
  mutate(z_trial = 0)

pred <- bind_rows(
fitted(bm_cs_s1, newdata = nd1, re_formula = NA) %>% as_tibble() %>% bind_cols(nd1)%>%mutate(study = "study1", task = "card_sorting"),
fitted(bm_cs_s2, newdata = nd2, re_formula = NA) %>% as_tibble() %>% bind_cols(nd2)%>%mutate(study = "study2", task = "card_sorting"),
fitted(bm_cs_s3, newdata = nd3, re_formula = NA) %>% as_tibble() %>% bind_cols(nd3)%>%mutate(study = "study3", task = "card_sorting"),

fitted(bm_me_s1, newdata = nd1, re_formula = NA) %>% as_tibble() %>% bind_cols(nd1)%>%mutate(study = "study1", task = "mutual_exclusivity"),
fitted(bm_me_s2, newdata = nd2, re_formula = NA) %>% as_tibble() %>% bind_cols(nd2)%>%mutate(study = "study2", task = "mutual_exclusivity"),
fitted(bm_me_s3, newdata = nd3, re_formula = NA) %>% as_tibble() %>% bind_cols(nd3)%>%mutate(study = "study3", task = "mutual_exclusivity"),

fitted(bm_ad_s2, newdata = nd2, re_formula = NA) %>% as_tibble() %>% bind_cols(nd2)%>%mutate(study = "study2", task = "ad_hoc_implicature"),
fitted(bm_ad_s3, newdata = nd3, re_formula = NA) %>% as_tibble() %>% bind_cols(nd3)%>%mutate(study = "study3", task = "ad_hoc_implicature"),

fitted(bm_dis_s2, newdata = nd2, re_formula = NA) %>% as_tibble() %>% bind_cols(nd2)%>%mutate(study = "study2", task = "discourse_continuity"),

fitted(bm_inf_s1, newdata = nd1, re_formula = NA) %>% as_tibble() %>% bind_cols(nd1)%>%mutate(study = "study1", task = "informativeness"),

fitted(bm_ms_s3, newdata = nd3, re_formula = NA) %>% as_tibble() %>% bind_cols(nd3)%>%mutate(study = "study3", task = "match_to_sample"),

fitted(bm_nov_s1, newdata = nd1, re_formula = NA) %>% as_tibble() %>% bind_cols(nd1)%>%mutate(study = "study1", task = "novelty"),

fitted(bm_pref_s1, newdata = nd1, re_formula = NA) %>% as_tibble() %>% bind_cols(nd1)%>%mutate(study = "study1", task = "preference"),

fitted(bm_simpinf_s2, newdata = nd2, re_formula = NA) %>% as_tibble() %>% bind_cols(nd2)%>%mutate(study = "study2", task = "simple_inf"),
fitted(bm_simpinf_s3, newdata = nd3, re_formula = NA) %>% as_tibble() %>% bind_cols(nd3)%>%mutate(study = "study3", task = "simple_inf")

)%>%
  mutate(task = factor(task, levels = c("mutual_exclusivity", "informativeness", "simple_inf", "preference", "novelty","card_sorting", "discourse_continuity", "ad_hoc_implicature", "match_to_sample")))
```

The next code section produces Figure 2 in the manuscript

```{r}
p1 <- data %>%
  group_by(study, id,age, subage,task) %>%
  filter(task != "training") %>%
  summarise(mean = mean(correct))%>%
  mutate(task = factor(task, levels = c("mutual_exclusivity", "informativeness", "simple_inf", "preference", "novelty","card_sorting", "discourse_continuity", "ad_hoc_implicature", "match_to_sample")))

p2 <- p1 %>%
  group_by(study,subage,task) %>%
  tidyboot_mean(column = mean) %>%
  mutate(chance = ifelse(task == "discourse_continuity", 1/3, 1/2))

task_names <- c(
                    `mutual_exclusivity` = "Mutual Exclusivity",
                    `informativeness` = "Informativeness Inference (1)",
                    `simple_inf` = "Informativeness Inference (2)",
                    `preference` = "Speaker Preference",
                    `novelty` = "Discourse Novelty",
                    `card_sorting` = "Card Sorting",
                    `discourse_continuity` = "Discourse Continuity",
                    `ad_hoc_implicature` = "Ad-hoc Implicature",
                    `match_to_sample` = "Relational Match-to-sample"
                    )

pf2 <- ggplot()+
  geom_hline(data = p2, aes(yintercept = chance), lty = 3)+
  geom_jitter(data = p1, aes(x = age, y = mean, col = study), alpha = .25, width = .05, height = .01)+
  geom_smooth(data = pred, aes(x = age, y = Estimate, ymin = Q2.5, ymax = Q97.5, col =study), stat = "identity", size = 1, alpha = .25)+
  facet_wrap(~task, nrow = 2, labeller = as_labeller(task_names))+
    geom_pointrange(data = p2, aes(x = as.numeric(as.character(subage))+.5, y = mean, ymin = ci_lower, ymax = ci_upper, col = study), position = position_dodge(width = .5))+
  labs(x = "Age", y = "Proportion correct") +
  scale_color_colorblind(name = "Study", labels = c("Study 1", "Study 2", "Study 3"))+
  ylim(-0.05, 1.05)+
  #scale_shape_manual(values=c(1, 2, 4), name = "Study", labels = c("Study 1", "Study 2", "Study 3"))+
  #scale_linetype_manual(values=c(1, 2, 3), name = "Study", labels = c("Study 1", "Study 2", "Study 3"))+
  theme_few()+
  theme(legend.position = c(.9,.225), legend.direction = "vertical", legend.box = "horizontal")
  #theme(legend.position = "bottom", legend.direction = "horizontal", legend.box = "horizontal")
  #guides(shape = guide_legend(order = 2),linetype = guide_legend(order = 2), col = guide_legend(order = 1))

ggsave(plot = pf2,"../paper/figures/figure2_2.png", width = 10, height = 4.5, scale = 1)
```

The following two sections extract the age estimates from the models for the different tasks and studies and visualizes them. The second plot is Figure 3 from the paper.

```{r}

est <- bind_rows(
posterior_samples(bm_cs_s1, pars = "b_z_age")%>%mutate(study = "study1", task = "card_sorting"),
posterior_samples(bm_cs_s2, pars = "b_z_age")%>%mutate(study = "study2", task = "card_sorting"),
posterior_samples(bm_cs_s3, pars = "b_z_age")%>%mutate(study = "study3", task = "card_sorting"),

posterior_samples(bm_me_s1, pars = "b_z_age")%>%mutate(study = "study1", task = "mutual_exclusivity"),
posterior_samples(bm_me_s2, pars = "b_z_age")%>%mutate(study = "study2", task = "mutual_exclusivity"),
posterior_samples(bm_me_s3, pars = "b_z_age")%>%mutate(study = "study3", task = "mutual_exclusivity"),

posterior_samples(bm_ad_s2, pars = "b_z_age")%>%mutate(study = "study2", task = "ad_hoc_implicature"),
posterior_samples(bm_ad_s3, pars = "b_z_age")%>%mutate(study = "study3", task = "ad_hoc_implicature"),

posterior_samples(bm_dis_s2, pars = "b_z_age")%>%mutate(study = "study2", task = "discourse_continuity"),

posterior_samples(bm_inf_s1, pars = "b_z_age")%>%mutate(study = "study1", task = "informativeness"),

posterior_samples(bm_ms_s3, pars = "b_z_age")%>%mutate(study = "study3", task = "match_to_sample"),

posterior_samples(bm_nov_s1, pars = "b_z_age")%>%mutate(study = "study1", task = "novelty"),

posterior_samples(bm_pref_s1, pars = "b_z_age")%>%mutate(study = "study1", task = "preference"),

posterior_samples(bm_simpinf_s2, pars = "b_z_age")%>%mutate(study = "study2", task = "simple_inf"),
posterior_samples(bm_simpinf_s3, pars = "b_z_age")%>%mutate(study = "study3", task = "simple_inf")

)%>%
  mutate(task = factor(task, levels = c("mutual_exclusivity", "informativeness", "simple_inf", "preference", "novelty","card_sorting", "discourse_continuity", "ad_hoc_implicature", "match_to_sample")),
         task = recode(task,
                    `mutual_exclusivity` = "Mutual Exclusivity",
                    `informativeness` = "Informativeness Inference (1)",
                    `simple_inf` = "Informativeness Inference (2)",
                    `preference` = "Speaker Preference",
                    `novelty` = "Discourse Novelty",
                    `card_sorting` = "Card Sorting",
                    `discourse_continuity` = "Discourse Continuity",
                    `ad_hoc_implicature` = "Ad-hoc Implicature",
                    `match_to_sample` = "Relational Match-to-sample"))



pest <- ggplot(est, aes(y = task, x = b_z_age, fill = study))+
geom_density_ridges(alpha = .5)+
  labs(y="", x="Model estimate for age")+
  geom_vline(xintercept = 0, col = "black", lty = 2, alpha = 0.75)+
  #scale_fill_manual(values = c("#FF0000A0", "#A0A0A0A0", "#FF0000A0"))+
  scale_fill_colorblind(name = "Study", labels = c("Study 1", "Study 2", "Study 3"))+
  #guides(fill = F)+
  theme_few()+ 
  xlim(-2,12)+
  scale_y_discrete(limits=rev)

ggsave(plot = pest,"../paper/figures/figure3.png", width = 7, height = 5, scale = 1.25)
```

```{r}

range <- bind_rows(
fixef(bm_cs_s1)%>%as_tibble(rownames = "parameter")%>%filter(parameter == "z_age")%>%mutate(study = "study1", task = "card_sorting"),
fixef(bm_cs_s2)%>%as_tibble(rownames = "parameter")%>%filter(parameter == "z_age")%>%mutate(study = "study2", task = "card_sorting"),
fixef(bm_cs_s3)%>%as_tibble(rownames = "parameter")%>%filter(parameter == "z_age")%>%mutate(study = "study3", task = "card_sorting"),

fixef(bm_me_s1)%>%as_tibble(rownames = "parameter")%>%filter(parameter == "z_age")%>%mutate(study = "study1", task = "mutual_exclusivity"),
fixef(bm_me_s2)%>%as_tibble(rownames = "parameter")%>%filter(parameter == "z_age")%>%mutate(study = "study2", task = "mutual_exclusivity"),
fixef(bm_me_s3)%>%as_tibble(rownames = "parameter")%>%filter(parameter == "z_age")%>%mutate(study = "study3", task = "mutual_exclusivity"),

fixef(bm_ad_s2)%>%as_tibble(rownames = "parameter")%>%filter(parameter == "z_age")%>%mutate(study = "study2", task = "ad_hoc_implicature"),
fixef(bm_ad_s3)%>%as_tibble(rownames = "parameter")%>%filter(parameter == "z_age")%>%mutate(study = "study3", task = "ad_hoc_implicature"),

fixef(bm_dis_s2)%>%as_tibble(rownames = "parameter")%>%filter(parameter == "z_age")%>%mutate(study = "study2", task = "discourse_continuity"),

fixef(bm_inf_s1)%>%as_tibble(rownames = "parameter")%>%filter(parameter == "z_age")%>%mutate(study = "study1", task = "informativeness"),

fixef(bm_ms_s3)%>%as_tibble(rownames = "parameter")%>%filter(parameter == "z_age")%>%mutate(study = "study3", task = "match_to_sample"),

fixef(bm_nov_s1)%>%as_tibble(rownames = "parameter")%>%filter(parameter == "z_age")%>%mutate(study = "study1", task = "novelty"),

fixef(bm_pref_s1)%>%as_tibble(rownames = "parameter")%>%filter(parameter == "z_age")%>%mutate(study = "study1", task = "preference"),

fixef(bm_simpinf_s2)%>%as_tibble(rownames = "parameter")%>%filter(parameter == "z_age")%>%mutate(study = "study2", task = "simple_inf"),
fixef(bm_simpinf_s3)%>%as_tibble(rownames = "parameter")%>%filter(parameter == "z_age")%>%mutate(study = "study3", task = "simple_inf")

)%>%
  mutate(task = factor(task, levels = c("mutual_exclusivity", "informativeness", "simple_inf", "preference", "novelty","card_sorting", "discourse_continuity", "ad_hoc_implicature", "match_to_sample")),
         task = recode(task,
                    `mutual_exclusivity` = "Mutual Exclusivity",
                    `informativeness` = "Informativeness Inference (1)",
                    `simple_inf` = "Informativeness Inference (2)",
                    `preference` = "Speaker Preference",
                    `novelty` = "Discourse Novelty",
                    `card_sorting` = "Card Sorting",
                    `discourse_continuity` = "Discourse Continuity",
                    `ad_hoc_implicature` = "Ad-hoc Implicature",
                    `match_to_sample` = "Relational Match-to-sample"))

prange<- ggplot(range, aes(y = task, x = Estimate, col = study))+
  geom_errorbarh(aes(xmin = Q2.5, xmax = Q97.5), position = position_dodge(width = 0.5), height = 0)+
  geom_point( position = position_dodge(width = 0.5),  size =1.5)+
  labs(y="", x="Model estimate for age")+
  geom_vline(xintercept = 0, col = "black", lty = 2, alpha = 0.75)+
  #scale_fill_manual(values = c("#FF0000A0", "#A0A0A0A0", "#FF0000A0"))+
  scale_color_colorblind(name = "Study", labels = c("Study 1", "Study 2", "Study 3"))+
  #guides(fill = F)+
  theme_few()+ 
  #xlim(-2,12)+
  scale_y_discrete(limits=rev)+
  theme(legend.position = c(.8,.8))

ggsave(plot = prange,"../paper/figures/figure3.png", width = 4, height = 2.5, scale = 1.5)
```

# Reliability

The following section implements the Rouder and Haaf (2019) method of estimating re-test reliability based on a GLMM. 

```{r}
model_cor <- data_frame()

tasks1 <- unique(data$task[data$study == "study1"])

for(i in tasks1) {

  model <- brm(correct ~  z_age + (0+test_day|id),
            data = data%>%filter(study == "study1", task == i), 
            family = bernoulli(),
          #control = list(adapt_delta = 0.99),
          sample_prior = F,
          chains = 4,
          cores = 4,
          #save_all_pars = TRUE,
          iter = 4000)

          cor <- summary(model)$random$id%>%as_tibble(rownames = "parameter")%>%filter(parameter == "cor(test_day1,test_day2)")%>%mutate(task = i , study = "study1")
          
          model_cor <- bind_rows(model_cor, cor)
  
}

tasks2 <- unique(data$task[data$study == "study2"])

for(i in tasks2) {

  model <- brm(correct ~  z_age + (0+test_day|id),
            data = data%>%filter(study == "study2", task == i), 
            family = bernoulli(),
          #control = list(adapt_delta = 0.99),
          sample_prior = F,
          chains = 4,
          cores = 4,
          #save_all_pars = TRUE,
          iter = 4000)

          cor <- summary(model)$random$id%>%as_tibble(rownames = "parameter")%>%filter(parameter == "cor(test_day1,test_day2)")%>%mutate(task = i , study = "study2")
          
          model_cor <- bind_rows(model_cor, cor)
  
}


mcor <- model_cor %>%
    mutate(task = recode(task,
                    `mutual_exclusivity` = "Mutual Exclusivity",
                    `informativeness` = "Informativeness Inference (1)",
                    `simple_inf` = "Informativeness Inference (2)",
                    `preference` = "Speaker Preference",
                    `novelty` = "Discourse Novelty",
                    `card_sorting` = "Card Sorting",
                    `discourse_continuity` = "Discourse Continuity",
                    `ad_hoc_implicature` = "Ad-hoc Implicature",
                    `match_to_sample` = "Relational Match-to-sample"),
           term = task, 
           mcor = Estimate, 
           mcor_lci = `l-95% CI`, 
           mcor_uci = `u-95% CI`)%>%
  select(study, term, task, mcor, mcor_lci, mcor_uci)

saveRDS(mcor, "../saves/model_based_reliability.rds")

mcor <- readRDS("../saves/model_based_reliability.rds")
```

The next section computes re-test reliability and correlations between tasks based on the aggregated raw scores. The plot generated at the end is Figure 4 from the paper. 

```{r}
wide_data <- data %>%
  mutate(task = recode(task,
                    `mutual_exclusivity` = "Mutual Exclusivity",
                    `informativeness` = "Informativeness Inference (1)",
                    `simple_inf` = "Informativeness Inference (2)",
                    `preference` = "Speaker Preference",
                    `novelty` = "Discourse Novelty",
                    `card_sorting` = "Card Sorting",
                    `discourse_continuity` = "Discourse Continuity",
                    `ad_hoc_implicature` = "Ad-hoc Implicature",
                    `match_to_sample` = "Relational Match-to-sample"))%>%
  filter(study != "study3",
         task != "training") %>%
  droplevels() %>%
  group_by(study,id,task, test_day) %>%
  summarise(mean = mean(correct)) %>%
  spread(test_day, mean) %>%
  na.omit() %>%
  rename("Day1" = `day1`,
         "Day2" = `day2`)

reli <- wide_data %>%
  group_by(study, task) %>%
  summarize(reli = cor.test(Day1,Day2)$estimate,
            lci = cor.test(Day1,Day2)$conf.int[1],
            uci = cor.test(Day1,Day2)$conf.int[2],
            p = cor.test(Day1,Day2)$p.value,
            n = n()) %>%
  mutate_if(is.numeric, round, digits = 2)


cor_r1 <- data %>%
  mutate(task = recode(task,
                    `mutual_exclusivity` = "Mutual Exclusivity",
                    `informativeness` = "Informativeness Inference (1)",
                    `simple_inf` = "Informativeness Inference (2)",
                    `preference` = "Speaker Preference",
                    `novelty` = "Discourse Novelty",
                    `card_sorting` = "Card Sorting",
                    `discourse_continuity` = "Discourse Continuity",
                    `ad_hoc_implicature` = "Ad-hoc Implicature",
                    `match_to_sample` = "Relational Match-to-sample"))%>%
  filter(study == "study1") %>%
  droplevels() %>%
  group_by(id,task) %>%
  summarise(mean = mean(correct)) %>%
  spread(task, mean) %>%
  ungroup() %>%
  select(-id) %>%
  corrr::correlate(diagonal = reli %>%
                     filter(study == "study1") %>%
                     pull(reli)) %>%
  gather(task, cor, -term) %>%
  mutate(cor = replace(cor, duplicated(cor), NA)) %>%
  mutate_if(is.numeric, round, digits = 2) %>%
  na.omit() %>%
  mutate(study = "study1")%>%
  left_join(mcor)%>%
  mutate(cor2 = ifelse(!is.na(mcor), paste0(" ",cor,"\n"," [",round(mcor,2), "]"), cor))


cor_r2 <- data%>%
    mutate(task = recode(task,
                    `mutual_exclusivity` = "Mutual Exclusivity",
                    `informativeness` = "Informativeness Inference (1)",
                    `simple_inf` = "Informativeness Inference (2)",
                    `preference` = "Speaker Preference",
                    `novelty` = "Discourse Novelty",
                    `card_sorting` = "Card Sorting",
                    `discourse_continuity` = "Discourse Continuity",
                    `ad_hoc_implicature` = "Ad-hoc Implicature",
                    `match_to_sample` = "Relational Match-to-sample"))%>%
  filter(study == "study2") %>%
  droplevels() %>%
  group_by(id,task) %>%
  summarise(mean = mean(correct)) %>%
  spread(task, mean) %>%
  ungroup() %>%
  select(-id) %>%
  corrr::correlate(diagonal = reli%>%filter(study == "study2") %>%pull(reli)) %>%
  gather(task, cor, -term) %>%
  mutate(cor = replace(cor, duplicated(cor), NA)) %>%
  mutate_if(is.numeric, round, digits = 2) %>%
  na.omit() %>%
  mutate(study = "study2")%>%
  left_join(mcor)%>%
  mutate(cor2 = ifelse(!is.na(mcor), paste0(" ",cor,"\n"," [",round(mcor,2), "]"), cor))

cor3 <- data%>%
    mutate(task = recode(task,
                    `mutual_exclusivity` = "Mutual Exclusivity",
                    `informativeness` = "Informativeness Inference (1)",
                    `simple_inf` = "Informativeness Inference (2)",
                    `preference` = "Speaker Preference",
                    `novelty` = "Discourse Novelty",
                    `card_sorting` = "Card Sorting",
                    `discourse_continuity` = "Discourse Continuity",
                    `ad_hoc_implicature` = "Ad-hoc Implicature",
                    `match_to_sample` = "Relational Match-to-sample"))%>%
  filter(study == "study3")%>%
  filter(task != "training")%>%
  droplevels()%>%
  group_by(id,task)%>%
  summarise(mean = mean(correct))%>%
  spread(task, mean)%>%
  ungroup()%>%
  select(-id)%>%
  corrr::correlate(diagonal = c(1,1.1,1.2,1.3,1.4))%>%
  gather(task, cor, -term)%>%
  mutate(cor = replace(cor, duplicated(cor), NA))%>%
  mutate_if(is.numeric, round, digits = 2)%>%
  na.omit()%>%
  mutate(study = "study3",
         cor = ifelse(cor>0.99,NA,cor))


cp1 <- ggplot(cor_r1, aes(x = term, y = task, fill = cor))+
  geom_tile(color = "white")+
  labs(x = "", y = "")+
  scale_fill_gradient2(low = "#CC6677", high = "#117733", mid = "white",
   midpoint = 0, limit = c(-1,1), space = "Lab",
   name="Correlation") +
   coord_fixed()+
  theme_few()+
  geom_text(aes(label = cor2), color = "black", size = 3) +
  #ggtitle("Study 1")+
  theme(
        legend.position = "right",
        legend.direction = "vertical",
        axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))

cp2 <- ggplot(cor_r2, aes(x = term, y = task, fill = cor))+
  geom_tile(color = "white")+
  labs(x = "", y = "")+
  scale_fill_gradient2(low = "#CC6677", high = "#117733", mid = "white",
   midpoint = 0, limit = c(-1,1), space = "Lab",
   name="Correlation") +
   coord_fixed()+
  theme_few()+
  geom_text(aes(label = cor2), color = "black", size = 3) +
  #ggtitle("Study 2")+
  theme(
        legend.position = "right",
        legend.direction = "vertical",
        axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))

cp3 <- ggplot(cor3, aes(x = term, y = task, fill = cor))+
  geom_tile(color = "white")+
  labs(x = "", y = "")+
  scale_fill_gradient2(low = "#CC6677", high = "#117733", mid = "white",
   midpoint = 0, limit = c(-1,1), space = "Lab",
   name="Correlation") +
   coord_fixed()+
  theme_few(base_size = 12)+
  #ggtitle("Study 3")+
  geom_text(aes(label = cor), color = "black", size = 3) +
  theme(legend.justification = c(1, 0),
        legend.position = c(0.55, 0.75),
        legend.direction = "vertical",
        axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
        legend.background = element_blank())+
  guides(fill = guide_colorbar(barwidth = 7, barheight = 1,
                title.position = "top", title.hjust = 0.5))

pf4 <- ggarrange(cp1, cp2, cp3, common.legend = T, legend = "right", nrow = 1, labels = c("A","B","C"), hjust = -1.5)

ggsave(plot = pf4,"./figures/figure4.png", width = 10, height = 3, scale = 1.5, bg = "white")
```

#Relations between tasks

The following section computes the correlation between tasks, including 95% confidence intervals.

```{r}
study = unique(data$study)
task1 = unique(data$task)
task2 = unique(data$task)

cor_data <- data_frame()

for (i in study){
  for(j in task1){
    for(k in task2){
 
  d <- data%>%
  filter(study == i,
         task == j | task == k,
         j != k)%>%
  group_by(id,task)%>%
  summarise(mean = mean(correct))%>%
  spread(task, mean)
  
  if(j != k  & ncol(d)>2){
  
  d <- d%>%rename(task1 = 2, task2 = 3)
    
  rho =cor.test(d$task1,d$task2)$estimate
  lci =cor.test(d$task1,d$task2)$conf.int[1]
  uci =cor.test(d$task1,d$task2)$conf.int[2]
  p =cor.test(d$task1,d$task2)$p.value

  cor = tibble(study = i, task1 = j, task2 = k, rho = rho, lci = lci, uci = uci, p = p)
  } else {
  cor = tibble(study = i, task1 = j, task2 = k, rho = NA, lci = NA, uci = NA, p = NA)
  }
  
  cor_data <- bind_rows(cor_data, cor)
     
      
    }
  }
}

cors <- cor_data%>%
  filter(!is.na(rho))%>%
  mutate_if(is.numeric, round,2)

write_csv(cors, "../saves/by_task_correlations.csv")
```

# Confirmatory factor analysis

The next section prepares the data file for the CFA.

```{r}
cfad <- data%>%
  group_by(id,age, subage,task)%>%
  filter(task != "training")%>%
  summarise(mean = mean(correct))%>%
  pivot_wider(names_from = "task", values_from = "mean")%>%
  ungroup()%>%
  filter(!is.na(ad_hoc_implicature),
         !is.na(card_sorting),
         !is.na(match_to_sample),
         !is.na(mutual_exclusivity),
         !is.na(simple_inf))%>%
  mutate(ad_hoc_implicature = scale(ad_hoc_implicature),
         card_sorting = scale(card_sorting),
         match_to_sample = scale(match_to_sample),
         mutual_exclusivity = scale(mutual_exclusivity),
         simple_inf = scale(simple_inf))
```

Here we specify the different CFA models, with `model` being the focal model.

```{r}
model <- 'prag  =~ ad_hoc_implicature + mutual_exclusivity + simple_inf
          card  =~ card_sorting
          match =~ match_to_sample'

model2 <- 'fac  =~ ad_hoc_implicature + mutual_exclusivity+ simple_inf + card_sorting + match_to_sample'

model3 <- 'ad  =~ ad_hoc_implicature
           simp  =~ simple_inf
           mut  =~ mutual_exclusivity
           card  =~ card_sorting
           match =~ match_to_sample'
```

Here we run the three CFA models.

```{r}
# fit <- bcfa(model, data = cfad, bcontrol = list(cores = 4), target = "stan", n.chains = 4, burnin = 5000, sample = 5000)
# saveRDS(fit, "../saves/bcfa_prag.rds")
fit <- readRDS("../saves/bcfa_prag.rds")

# fit2 <- bcfa(model2, data = cfad, bcontrol = list(cores = 4), target = "stan", n.chains = 4, burnin = 5000, sample = 5000)
# saveRDS(fit2, "../saves/bcfa_single.rds")
fit2 <- readRDS("../saves/bcfa_single.rds")

# fit3 <- bcfa(model3, data = cfad, bcontrol = list(cores = 4), target = "stan", n.chains = 4, burnin = 5000, sample = 5000)
# saveRDS(fit3, "../saves/bcfa_separate.rds")
fit3 <- readRDS("../saves/bcfa_separate.rds")


```

The following section extracts the fit measures (e.g., PPP) for the three models. 

```{r}
bind_rows(
fitmeasures(fit)%>%as_tibble(rownames = "index")%>%
  mutate(model = "fit1"),
fitmeasures(fit2)%>%as_tibble(rownames = "index")%>%
  mutate(model = "fit2"),
fitmeasures(fit3)%>%as_tibble(rownames = "index")%>%
  mutate(model = "fit3")
)%>%
  write_csv("../saves/cfa_fit_measures.csv")
```

Here we extract the WAIC value for each model and compute the WAIC weight. We do the same for LOO. 

```{r}
# fit_waic <- fitmeasures(fit)%>%as_tibble(rownames = "index")%>%filter(index == "waic")%>%pull(value)
# fit2_waic <- fitmeasures(fit2)%>%as_tibble(rownames = "index")%>%filter(index == "waic")%>%pull(value)
# fit3_waic <- fitmeasures(fit3)%>%as_tibble(rownames = "index")%>%filter(index == "waic")%>%pull(value)
# 
# fit_se_waic <- fitmeasures(fit)%>%as_tibble(rownames = "index")%>%filter(index == "se_waic")%>%pull(value)
# fit2_se_waic <- fitmeasures(fit2)%>%as_tibble(rownames = "index")%>%filter(index == "se_waic")%>%pull(value)
# fit3_se_waic <- fitmeasures(fit3)%>%as_tibble(rownames = "index")%>%filter(index == "se_waic")%>%pull(value)
# 
# fit_looic <- fitmeasures(fit)%>%as_tibble(rownames = "index")%>%filter(index == "looic")%>%pull(value)
# fit2_looic <- fitmeasures(fit2)%>%as_tibble(rownames = "index")%>%filter(index == "looic")%>%pull(value)
# fit3_looic <- fitmeasures(fit3)%>%as_tibble(rownames = "index")%>%filter(index == "looic")%>%pull(value)
# 
# fit_se_looic <- fitmeasures(fit)%>%as_tibble(rownames = "index")%>%filter(index == "se_loo")%>%pull(value)
# fit2_se_looic <- fitmeasures(fit2)%>%as_tibble(rownames = "index")%>%filter(index == "se_loo")%>%pull(value)
# fit3_se_looic <- fitmeasures(fit3)%>%as_tibble(rownames = "index")%>%filter(index == "se_loo")%>%pull(value)
# 
# #model weights
# ## waic
# w1 <- exp(-0.5*(fit_waic-fit_waic))/(exp(-0.5*(fit_waic-fit_waic))+exp(-0.5*(fit2_waic-fit_waic))+exp(-0.5*7.1)+exp(-0.5*(fit3_waic-fit_waic)))
# w2 <- exp(-0.5*(fit2_waic-fit_waic))/(exp(-0.5*(fit_waic-fit_waic))+exp(-0.5*(fit2_waic-fit_waic))+exp(-0.5*7.1)+exp(-0.5*(fit3_waic-fit_waic)))
# w3 <- exp(-0.5*(fit3_waic-fit_waic))/(exp(-0.5*(fit_waic-fit_waic))+exp(-0.5*(fit2_waic-fit_waic))+exp(-0.5*7.1)+exp(-0.5*(fit3_waic-fit_waic)))
# ## looic
# l1 <- exp(-0.5*(fit_looic-fit_looic))/(exp(-0.5*(fit_looic-fit_looic))+exp(-0.5*(fit2_looic-fit_looic))+exp(-0.5*7.1)+exp(-0.5*(fit3_looic-fit_waic)))
# l2 <- exp(-0.5*(fit2_looic-fit_looic))/(exp(-0.5*(fit_looic-fit_looic))+exp(-0.5*(fit2_looic-fit_looic))+exp(-0.5*7.1)+exp(-0.5*(fit3_looic-fit_waic)))
# l3 <- exp(-0.5*(fit3_looic-fit_looic))/(exp(-0.5*(fit_looic-fit_looic))+exp(-0.5*(fit2_looic-fit_looic))+exp(-0.5*7.1)+exp(-0.5*(fit3_looic-fit_waic)))
# 
# model_comparison <- tibble(
#   model = c("fit1", "fit2", "fit3"),
#   waic = c(fit_waic, fit2_waic, fit3_waic), 
#   waic_se = c(fit_se_waic, fit2_se_waic, fit3_se_waic), 
#   waic_weight = c(w1, w2, w3),
#   looic = c(fit_looic, fit2_looic, fit3_looic),
#   looic_se = c(fit_se_looic, fit2_se_looic, fit3_se_looic),
#   looic_weight = c(l1, l2, l3)
# )%>%
#   arrange(waic)%>%
#   write_csv(., "../saves/bcfa_model_comparison.csv")

model_comparison <- read_csv("../saves/bcfa_model_comparison.csv")

```

# RSA model 

First we read in the saved model output

```{r}
rsa_model <- readRDS("../saves/model_pragBat3.rds")
```

The next section visualizes the scale parameter

```{r}
scale <- rsa_model %>%
  filter(parameter == "speaker_optimality",
         token == "scale_parameter")

pscale <- ggplot(scale, aes(x = value))+
  geom_density( alpha = 0.3, aes(fill = id), col = "black", adjust = 3)+
  geom_vline(xintercept = 1, lty = 2, col = "black", alpha = .75)+
  xlab("Scale parameter")+
  ylab("Density")+
  #facet_grid(~id, scale = "free_x")+
  theme_few()+
  scale_fill_viridis_d(name = "Task", labels = c("Informativeness inference", "Mutual exclusivity"))+
  theme(legend.position = c(.6,.7))
```

Here we extract and summarize the person specific $\alpha$ estimates and correlate them to performance in the card sorting and relational match-to-sample tasks.

```{r}
so_est <- rsa_model %>%
  filter(parameter == "speaker_optimality",
         type == "subj_parameter",
         token == "speaker_optimality")%>%
  group_by(id)%>%
  summarise(mode = estimate_mode(value),
            uci = hdi_upper(value),
            lci = hdi_lower(value))

rsa <- data%>%
  filter(study == "study3", task == "card_sorting" | task == "match_to_sample")%>%
  group_by(id, task)%>%
  summarise(mean = mean(correct))%>%
  mutate(id = str_remove(id, "study3_"))%>%
  ungroup()%>%
  left_join(so_est)%>%
    mutate(task = recode(task,
                    `card_sorting` = "Card Sorting",
                    `match_to_sample` = "Relational Match-to-sample"))

cor <- rsa%>%
  group_by(task)%>%
  summarize(cor = round(cor.test(mean,mode)$estimate,2),
            lci =  round(cor.test(mean,mode)$conf.int[1],2),
            uci =  round(cor.test(mean,mode)$conf.int[2],2))%>%
  mutate(label = paste0("r = ", cor, " (",lci, " - ", uci,")"))

write_csv(cor, "../saves/rsa_cor_estimates.csv")

prsacor <- ggplot(rsa, aes(x = mode, y = mean))+
  #geom_abline(intercept = 2, slope = 1, lty = 2, alpha = .75)+
  geom_point(pch = 1, alpha = .75)+
  geom_smooth(method = "lm", col= "firebrick")+
  geom_text(data = cor, aes(label = label),x = 1, y = 0.9)+
  labs(y = "Mean proportion correct", x = "RSA model estimate (\u03b1)")+
  facet_grid(~task)+
  theme_few()

```

The next section reads in the output from the RSA-based reliability model for Study 2

```{r}
rel_rsa_model <- readRDS("../saves/rsa_rel_est.rds")
```

Here we summarize the parameter estimates for each test session and correlate them to get a measure of re-test reliability. 

```{r}
so_id_summary <- rel_rsa_model%>%
  group_by(day,id)%>%
  summarise(mode = estimate_mode(value),
            uci = hdi_upper(value),
            lci = hdi_lower(value))%>%
  pivot_wider(names_from = c(day), values_from = c(mode,uci,lci))

cor <- tibble(cor =  paste0(
  "r = ",
  round(cor.test(so_id_summary$mode_1, so_id_summary$mode_2)$estimate, 2),
  " (",
  round(cor.test(so_id_summary$mode_1, so_id_summary$mode_2)$conf.int[1], 2),
  " - ",
  round(cor.test(so_id_summary$mode_1, so_id_summary$mode_2)$conf.int[2], 2),
  ")"
  )
  )


prelrsa <- ggplot(so_id_summary, aes(x = mode_1, y = mode_2))+
  geom_abline(intercept = 0, slope = 1, lty = 2, alpha = 0.7, size = 0.5)+
  geom_errorbar(aes(ymin = lci_2, ymax = uci_2),width = 0, alpha = .5, col = "grey")+
  geom_errorbarh(aes(xmin = lci_1, xmax = uci_1), height = 0, alpha = .5, col = "grey")+
    geom_point(pch = 1, size = 2)+
    labs(x = "Day 1", y = "Day 2")+
  scale_y_continuous(limits=c(0,8),oob=squish)+
  #facet_grid(~chain)+
  geom_text(data = cor, aes(label =  cor), x = 0, y =7.5, hjust = 0)+
  #stat_cor(method = "pearson", aes(x = mode_1, y = mode_2), inherit.aes = F, size = 3)+
  theme_few()
```

Here we combine the plots for the correlation between $\alpha$ estimates and the card sorting and relational match-to-sample tasks with the plot for the scale parameter and the RSA based reliability plot to generate Figure 6 in the manuscript. 

```{r}
prsa <- ggarrange(
  prsacor,
  ggarrange(prelrsa, pscale, nrow = 2  , labels = c("", "C")),
  widths = c(3,1),
  labels = c("A", "B")
)

ggsave(plot = prsa,"../paper/figures/figure6.png", width = 10, height = 4, scale = 1.25, bg = "white")
```

